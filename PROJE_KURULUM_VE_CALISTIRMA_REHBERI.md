# Proje Kurulum, Ã‡alÄ±ÅŸtÄ±rma ve Test Rehberi

## GiriÅŸ

Bu rehber, "Haber Makalesi SÄ±nÄ±flandÄ±rma ve Analiz" projesini baÅŸtan sona nasÄ±l kuracaÄŸÄ±nÄ±zÄ±, Ã§alÄ±ÅŸtÄ±racaÄŸÄ±nÄ±zÄ± ve test edeceÄŸinizi adÄ±m adÄ±m aÃ§Ä±klamaktadÄ±r. Projenin amacÄ±, verilen haber metinlerini NLP teknikleri kullanarak business, entertainment, politics, sport, ve tech gibi Ã¶nceden tanÄ±mlanmÄ±ÅŸ kategorilere ayÄ±rmaktÄ±r.

## BÃ¶lÃ¼m 1: Proje DosyalarÄ±nÄ±n HazÄ±rlanmasÄ±

1.  **Proje KlasÃ¶rÃ¼nÃ¼ OluÅŸturma:**
    *   BilgisayarÄ±nÄ±zda proje iÃ§in bir ana klasÃ¶r oluÅŸturun (Ã¶rneÄŸin, `NLP_Odevim`).

2.  **Gerekli DosyalarÄ± Kopyalama:**
    *   AÅŸaÄŸÄ±daki tÃ¼m dosyalarÄ± ve `images` klasÃ¶rÃ¼nÃ¼ bu ana klasÃ¶re (`NLP_Odevim`) kopyalayÄ±n:
        *   `News_Category_Dataset_v3.json` (Bu dosyayÄ± Kaggle'dan indirip ana klasÃ¶re kendiniz kopyalamalÄ±sÄ±nÄ±z.)
        *   `app.py` (Streamlit UygulamasÄ±)
        *   `bbc_news_classification_with_word2vec.ipynb` (Jupyter Notebook)
        *   `prepare_kaggle_dataset.py` (Veri HazÄ±rlama BetiÄŸi)
        *   `requirements.txt` (Gerekli KÃ¼tÃ¼phaneler)
        *   `README.md`
        *   `PROJECT_REPORT.md`
        *   `PRESENTATION.md`
        *   `SUMMARY.md`
        *   `KAGGLE_DATASET_KULLANIM_KILAVUZU.md`
        *   `.gitignore`
        *   `images/` (klasÃ¶r ve iÃ§indeki `bbc_logo.png`, `news_classification_icon.png`)

3.  **KlasÃ¶r YapÄ±sÄ± KontrolÃ¼:**
    *   Ana klasÃ¶rÃ¼nÃ¼zÃ¼n (`NLP_Odevim`) yapÄ±sÄ± ÅŸu ÅŸekilde gÃ¶rÃ¼nmelidir:

    ```
    NLP_Odevim/
    â”œâ”€â”€ News_Category_Dataset_v3.json
    â”œâ”€â”€ app.py
    â”œâ”€â”€ bbc_news_classification_with_word2vec.ipynb
    â”œâ”€â”€ prepare_kaggle_dataset.py
    â”œâ”€â”€ requirements.txt
    â”œâ”€â”€ README.md
    â”œâ”€â”€ PROJECT_REPORT.md
    â”œâ”€â”€ PRESENTATION.md
    â”œâ”€â”€ SUMMARY.md
    â”œâ”€â”€ KAGGLE_DATASET_KULLANIM_KILAVUZU.md
    â”œâ”€â”€ .gitignore
    â”œâ”€â”€ images/
    â”‚   â”œâ”€â”€ bbc_logo.png
    â”‚   â””â”€â”€ news_classification_icon.png
    â”œâ”€â”€ inputs/      (Bu klasÃ¶r prepare_kaggle_dataset.py Ã§alÄ±ÅŸtÄ±rÄ±lÄ±nca oluÅŸturulacak)
    â”œâ”€â”€ models/      (Bu klasÃ¶r prepare_kaggle_dataset.py Ã§alÄ±ÅŸtÄ±rÄ±lÄ±nca oluÅŸturulacak, notebook tarafÄ±ndan kullanÄ±lacak)
    â””â”€â”€ outputs/     (Bu klasÃ¶r prepare_kaggle_dataset.py Ã§alÄ±ÅŸtÄ±rÄ±lÄ±nca oluÅŸturulacak)
    ```

## BÃ¶lÃ¼m 2: Gerekli OrtamÄ±n Kurulumu

1.  **Python Kurulumu (EÄŸer Yoksa):**
    *   Python 3.8 veya Ã¼zeri bir sÃ¼rÃ¼mÃ¼n kurulu olduÄŸundan emin olun. Python'Ä± resmi web sitesinden indirebilirsiniz: [https://www.python.org/downloads/](https://www.python.org/downloads/)

2.  **Sanal Ortam OluÅŸturma (Ã–nemle Ã–nerilir):**
    *   Terminali (Komut Ä°stemi, PowerShell veya Linux/macOS terminali) proje ana klasÃ¶rÃ¼nde (`NLP_Odevim`) aÃ§Ä±n.
    *   AÅŸaÄŸÄ±daki komutla bir sanal ortam (`.venv` adÄ±nda) oluÅŸturun:
        ```bash
        python -m venv .venv
        ```

3.  **Sanal OrtamÄ± Aktif Etme:**
    *   **Windows iÃ§in:**
        ```bash
        .venv\Scripts\activate
        ```
    *   **Linux/macOS iÃ§in:**
        ```bash
        source .venv/bin/activate
        ```
    *   Sanal ortam aktif olduÄŸunda, terminalde komut satÄ±rÄ±nÄ±n baÅŸÄ±nda `(.venv)` ibaresi gÃ¶rÃ¼necektir.

4.  **Gerekli KÃ¼tÃ¼phaneleri YÃ¼kleme:**
    *   Aktif sanal ortamda, aÅŸaÄŸÄ±daki komutla `requirements.txt` dosyasÄ±ndaki tÃ¼m kÃ¼tÃ¼phaneleri yÃ¼kleyin:
        ```bash
        pip install -r requirements.txt
        ```
    *   Bu komut, projenin ihtiyaÃ§ duyduÄŸu `pandas`, `nltk`, `scikit-learn`, `gensim`, `streamlit`, `matplotlib`, `seaborn` gibi tÃ¼m kÃ¼tÃ¼phaneleri kuracaktÄ±r.

## BÃ¶lÃ¼m 3: Veri Setinin HazÄ±rlanmasÄ±

1.  **`News_Category_Dataset_v3.json` DosyasÄ±nÄ±n YerleÅŸimi:**
    *   Kaggle'dan indirdiÄŸiniz `News_Category_Dataset_v3.json` dosyasÄ±nÄ±n proje ana klasÃ¶rÃ¼nde (`NLP_Odevim`) olduÄŸundan emin olun.

2.  **Veri HazÄ±rlama BetiÄŸini Ã‡alÄ±ÅŸtÄ±rma:**
    *   Sanal ortamÄ±nÄ±z aktifken ve proje ana klasÃ¶rÃ¼ndeyken, aÅŸaÄŸÄ±daki komutu Ã§alÄ±ÅŸtÄ±rÄ±n:
        ```bash
        python prepare_kaggle_dataset.py
        ```
    *   Bu iÅŸlem `News_Category_Dataset_v3.json` dosyasÄ±nÄ± iÅŸleyerek `inputs/news_category_dataset.csv` dosyasÄ±nÄ± (BBC kategorilerine eÅŸlenmiÅŸ veri iÃ§erir) ve `inputs/category_mapping.json` dosyasÄ±nÄ± oluÅŸturacaktÄ±r. AyrÄ±ca `outputs` klasÃ¶rÃ¼ne `bbc_categories_distribution.png` adlÄ± bir kategori daÄŸÄ±lÄ±m grafiÄŸi kaydedecektir.
    *   Terminalde iÅŸlemin baÅŸarÄ±yla tamamlandÄ±ÄŸÄ±na dair mesajlarÄ± gÃ¶rmelisiniz.

## BÃ¶lÃ¼m 4: Jupyter Notebook'un Ã‡alÄ±ÅŸtÄ±rÄ±lmasÄ±, Model EÄŸitimi ve Test Edilmesi

Jupyter Notebook, veri Ã¶n iÅŸleme, Ã¶zellik Ã§Ä±karma, model eÄŸitimi, deÄŸerlendirme ve bu sÃ¼reÃ§lerin detaylÄ± analizini iÃ§erir.

1.  **Jupyter Notebook'u BaÅŸlatma:**
    *   Sanal ortamÄ±nÄ±z aktifken, terminalde aÅŸaÄŸÄ±daki komutu Ã§alÄ±ÅŸtÄ±rÄ±n:
        ```bash
        jupyter notebook
        ```
    *   Bu komut web tarayÄ±cÄ±nÄ±zda Jupyter arayÃ¼zÃ¼nÃ¼ aÃ§acaktÄ±r.

2.  **Notebook DosyasÄ±nÄ± AÃ§ma:**
    *   TarayÄ±cÄ±daki Jupyter arayÃ¼zÃ¼nden `bbc_news_classification_with_word2vec.ipynb` dosyasÄ±na tÄ±klayarak aÃ§Ä±n.

3.  **Notebook HÃ¼crelerini Ã‡alÄ±ÅŸtÄ±rma ve Metodolojiyi Anlama:**
    *   **Veri YÃ¼kleme HÃ¼cresini Kontrol Etme:** Notebook'un baÅŸÄ±ndaki veri yÃ¼kleme hÃ¼cresinin `pd.read_csv('inputs/news_category_dataset.csv')` ÅŸeklinde olduÄŸundan emin olun.
    *   HÃ¼creleri sÄ±rayla (`Shift+Enter` veya "Cell" > "Run Cells") Ã§alÄ±ÅŸtÄ±rarak adÄ±mlarÄ± takip edin.

    *   **4.1. Veri Ã–n Ä°ÅŸleme (Text Preprocessing):**
        *   **Metin Temizleme:** Ã–zel karakterlerin, sayÄ±larÄ±n ve gereksiz boÅŸluklarÄ±n kaldÄ±rÄ±lmasÄ± iÃ§in **Regular Expressions (RegEx)** kullanÄ±lmÄ±ÅŸtÄ±r.
        *   **Metin Normalizasyon:**
            *   **Lowercasing:** TÃ¼m metin kÃ¼Ã§Ã¼k harfe Ã§evrilmiÅŸtir.
            *   **Lemmatization (NLTK WordNetLemmatizer):** Kelimeler kÃ¶k formlarÄ±na (lemma) indirgenmiÅŸtir. Ã–rneÄŸin, "running" -> "run", "better" -> "good". Bu, kelime daÄŸarcÄ±ÄŸÄ±nÄ± azaltÄ±r ve modelin genelleme yapmasÄ±na yardÄ±mcÄ± olur.
            *   **Stop Words KaldÄ±rma (NLTK):** Ä°ngilizce iÃ§in yaygÄ±n olan ve anlam taÅŸÄ±mayan kelimeler (Ã¶rn: "the", "is", "in") metinden Ã§Ä±karÄ±lmÄ±ÅŸtÄ±r.
        *   **Tokenization (NLTK):** Metinler kelime listelerine (token) bÃ¶lÃ¼nmÃ¼ÅŸtÃ¼r.
        *   **Edit Distance (DÃ¼zeltme):** Bu projede doÄŸrudan bir edit distance tabanlÄ± yazÄ±m dÃ¼zeltme adÄ±mÄ± uygulanmamÄ±ÅŸtÄ±r. Lemmatization ve stop word kaldÄ±rma gibi adÄ±mlar, bazÄ± kÃ¼Ã§Ã¼k yazÄ±m hatalarÄ±nÄ±n etkisini dolaylÄ± olarak azaltabilir. Daha kapsamlÄ± bir yazÄ±m dÃ¼zeltme iÃ§in ek kÃ¼tÃ¼phaneler (Ã¶rn: `pyspellchecker`) entegre edilebilir, ancak bu projenin mevcut kapsamÄ±nda yer almamaktadÄ±r.

    *   **4.2. Ã–zellik Ã‡Ä±karma (Feature Engineering):**
        *   **Word2Vec (Gensim):** Kelimeleri yoÄŸun vektÃ¶r temsillerine dÃ¶nÃ¼ÅŸtÃ¼rmek iÃ§in Word2Vec modeli kullanÄ±lmÄ±ÅŸtÄ±r. Bu model, kelimelerin anlamsal benzerliklerini yakalayabilir. Her bir haber metni, iÃ§erdiÄŸi kelimelerin Word2Vec vektÃ¶rlerinin ortalamasÄ± alÄ±narak tek bir vektÃ¶rle temsil edilmiÅŸtir. Bu, metnin genel anlamsal iÃ§eriÄŸini yansÄ±tan bir Ã¶zelliktir.
        *   **N-gram Modelleri:**
            *   Bu projede Ã¶zellik Ã§Ä±karma aÅŸamasÄ±nda Word2Vec Ã¶ncelikli olarak kullanÄ±lmÄ±ÅŸtÄ±r. N-gram'lar (Ã¶rneÄŸin bigram veya trigram), metin iÃ§indeki ardÄ±ÅŸÄ±k kelime dizilerini analiz etmek iÃ§in gÃ¼Ã§lÃ¼ bir tekniktir ve TF-IDF gibi yÃ¶ntemlerle birleÅŸtirilerek Ã¶zellik olarak kullanÄ±labilir.
            *   Notebook'ta doÄŸrudan bir N-gram tabanlÄ± Ã¶zellik vektÃ¶rÃ¼ oluÅŸturulup sÄ±nÄ±flandÄ±rÄ±cÄ±ya verilmemiÅŸtir. Ancak, N-gram analizi, metinlerin yapÄ±sÄ±nÄ± ve sÄ±k kullanÄ±lan ifadeleri anlamak iÃ§in keÅŸifsel veri analizi (EDA) aÅŸamasÄ±nda veya Word2Vec'e alternatif/tamamlayÄ±cÄ± olarak dÃ¼ÅŸÃ¼nÃ¼lebilir.
            *   Ã–dev gereksinimlerinde N-gram analizi istendiÄŸi iÃ§in, `PROJECT_REPORT.md` dosyasÄ±nda N-gram'larÄ±n ne olduÄŸunu, nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ± ve bu projede neden Word2Vec'in tercih edildiÄŸi veya N-gram'larÄ±n nasÄ±l entegre edilebileceÄŸi tartÄ±ÅŸÄ±labilir.

    *   **4.3. Metin SÄ±nÄ±flandÄ±rma (Text Classification) - Model EÄŸitimi:**
        *   Veri seti, eÄŸitim (%80) ve test (%20) olmak Ã¼zere ikiye ayrÄ±lmÄ±ÅŸtÄ±r.
        *   AÅŸaÄŸÄ±daki sÄ±nÄ±flandÄ±rma algoritmalarÄ± denenmiÅŸ ve karÅŸÄ±laÅŸtÄ±rÄ±lmÄ±ÅŸtÄ±r:
            *   **Logistic Regression:** DoÄŸrusal bir modeldir, olasÄ±lÄ±ksal tahminler yapar.
            *   **Support Vector Machine (SVM):** Ã–zellikle yÃ¼ksek boyutlu uzaylarda etkili olan bir sÄ±nÄ±flandÄ±rÄ±cÄ±dÄ±r.
            *   **Naive Bayes:** OlasÄ±lÄ±ksal bir sÄ±nÄ±flandÄ±rÄ±cÄ±dÄ±r, kelime frekanslarÄ±na dayanÄ±r. (Bu projede doÄŸrudan kullanÄ±lmamÄ±ÅŸ olabilir, ancak Ã¶dev gereksinimlerinde alternatif olarak belirtilmiÅŸtir.)
            *   **Decision Trees / Random Forest:** Karar aÄŸacÄ± tabanlÄ± modellerdir. (Bu projede doÄŸrudan kullanÄ±lmamÄ±ÅŸ olabilir, ancak Ã¶dev gereksinimlerinde alternatif olarak belirtilmiÅŸtir.)
        *   SeÃ§ilen modeller, Word2Vec ile oluÅŸturulan metin vektÃ¶rleri ve bunlara karÅŸÄ±lÄ±k gelen kategori etiketleri kullanÄ±larak eÄŸitilmiÅŸtir.

    *   **4.4. Model DeÄŸerlendirme (Model Evaluation):**
        *   EÄŸitilen modellerin performansÄ± test seti Ã¼zerinde deÄŸerlendirilmiÅŸtir.
        *   **Ã–nemli Metrikler:**
            *   **Accuracy (DoÄŸruluk):** Modelin doÄŸru yaptÄ±ÄŸÄ± tahminlerin toplam tahmin sayÄ±sÄ±na oranÄ±. Genel performansÄ± gÃ¶sterir.
            *   **Precision (Kesinlik):** Bir kategori iÃ§in pozitif olarak tahmin edilen Ã¶rneklerden kaÃ§Ä±nÄ±n gerÃ§ekten pozitif olduÄŸu. (TP / (TP + FP)). YanlÄ±ÅŸ pozitiflerin maliyetli olduÄŸu durumlarda Ã¶nemlidir.
            *   **Recall (DuyarlÄ±lÄ±k veya Hassasiyet):** Bir kategorideki gerÃ§ekten pozitif olan Ã¶rneklerden kaÃ§Ä±nÄ±n model tarafÄ±ndan doÄŸru tahmin edildiÄŸi. (TP / (TP + FN)). YanlÄ±ÅŸ negatiflerin maliyetli olduÄŸu durumlarda Ã¶nemlidir.
            *   **F1-Score (F1 PuanÄ±):** Precision ve Recall metriklerinin harmonik ortalamasÄ±dÄ±r (2 * (Precision * Recall) / (Precision + Recall)). Dengesiz veri setlerinde veya hem precision hem de recall Ã¶nemli olduÄŸunda iyi bir Ã¶lÃ§Ã¼ttÃ¼r.
        *   Bu metrikler, her bir kategori iÃ§in ayrÄ± ayrÄ± ve genel (makro/mikro ortalamalar) olarak hesaplanmÄ±ÅŸtÄ±r. **SÄ±nÄ±flandÄ±rma Raporu (Classification Report)** bu metrikleri Ã¶zetler.
        *   **KarÄ±ÅŸÄ±klÄ±k Matrisi (Confusion Matrix):** Modelin hangi kategorileri birbiriyle karÄ±ÅŸtÄ±rdÄ±ÄŸÄ±nÄ± gÃ¶rsel olarak gÃ¶sterir. Matrisin kÃ¶ÅŸegenleri doÄŸru tahminleri, diÄŸer hÃ¼creler ise yanlÄ±ÅŸ tahminleri gÃ¶sterir.

    *   **4.5. Model Kaydetme:**
        *   Notebook'un sonlarÄ±na doÄŸru, genellikle en iyi performansÄ± veren sÄ±nÄ±flandÄ±rma modeli (Ã¶rneÄŸin, SVM) ve eÄŸitilmiÅŸ Word2Vec modeli, daha sonra Streamlit uygulamasÄ±nda kullanÄ±lmak Ã¼zere `models` klasÃ¶rÃ¼ne `.pkl` veya `.joblib` formatÄ±nda kaydedilmiÅŸtir.

## BÃ¶lÃ¼m 5: Streamlit Web UygulamasÄ±nÄ±n Ã‡alÄ±ÅŸtÄ±rÄ±lmasÄ± ve Test Edilmesi

Streamlit uygulamasÄ±, eÄŸittiÄŸiniz modeli kullanarak canlÄ± haber metni sÄ±nÄ±flandÄ±rmasÄ± yapmanÄ±zÄ± saÄŸlar.

1.  **Streamlit UygulamasÄ±nÄ± BaÅŸlatma:**
    *   Sanal ortamÄ±nÄ±z aktifken ve proje ana klasÃ¶rÃ¼ndeyken, (gerekirse) yeni bir terminal aÃ§Ä±n.
    *   AÅŸaÄŸÄ±daki komutu Ã§alÄ±ÅŸtÄ±rÄ±n:
        ```bash
        streamlit run app.py
        ```
    *   Bu komut web tarayÄ±cÄ±nÄ±zda Streamlit uygulamasÄ±nÄ± aÃ§acaktÄ±r.

2.  **Streamlit UygulamasÄ±nÄ± Test Etme AdÄ±mlarÄ±:**
    *   **ArayÃ¼z KontrolÃ¼:** UygulamanÄ±n baÅŸlÄ±ÄŸÄ±nÄ±n ("ğŸ“° BBC News Classifier"), Ã¶ÄŸrenci bilgilerinizin ve diÄŸer metinlerin doÄŸru gÃ¶rÃ¼ndÃ¼ÄŸÃ¼nÃ¼ kontrol edin.
    *   **Model YÃ¼kleme:** UygulamanÄ±n baÅŸlangÄ±Ã§ta `models` klasÃ¶rÃ¼nden kaydedilmiÅŸ sÄ±nÄ±flandÄ±rma modelini ve Word2Vec modelini baÅŸarÄ±yla yÃ¼klediÄŸinden emin olun.
    *   **Metin GiriÅŸi:** Kenar Ã§ubuÄŸundaki "Haber Metnini Girin" alanÄ±na Ã§eÅŸitli haber metinleri yapÄ±ÅŸtÄ±rÄ±n.
        *   Ã–rnekler iÃ§in Ã¶nceki yanÄ±tlara veya kendi bulacaÄŸÄ±nÄ±z haber metinlerine bakabilirsiniz.
    *   **SÄ±nÄ±flandÄ±rma Butonu:** "SÄ±nÄ±flandÄ±r" butonuna tÄ±klayÄ±n.
    *   **SonuÃ§larÄ± Ä°nceleme:** Tahmin edilen kategoriyi ve olasÄ±lÄ±k grafiÄŸini inceleyin.
    *   **KapsamlÄ± Test:** FarklÄ± kategorilerden, farklÄ± uzunluklarda ve belirsiz metinlerle testler yapÄ±n.

## BÃ¶lÃ¼m 6: Genel Proje DeÄŸerlendirmesi ve Raporlama

1.  **Ã–dev Gereksinimleri KontrolÃ¼:**
    *   Projenizin, Ã¶dev tanÄ±mÄ±nda belirtilen tÃ¼m NLP tekniklerini iÃ§erdiÄŸinden emin olun.

2.  **Rapor ve Sunum DosyalarÄ±:**
    *   `PROJECT_REPORT.md` ve `PRESENTATION.md` dosyalarÄ±nÄ±n metodolojinizi, veri setinizi, modelleri, sonuÃ§larÄ± ve metrikleri detaylÄ±ca aÃ§Ä±kladÄ±ÄŸÄ±nÄ± kontrol edin.
    *   **Ã–zellikle N-gram ve Edit Distance konularÄ±na deÄŸinin:** `PROJECT_REPORT.md` dosyasÄ±nda, N-gram modellerinin ne olduÄŸunu, kelime dizilerini analiz etmedeki Ã¶nemini, TF-IDF gibi yÃ¶ntemlerle nasÄ±l kullanÄ±labileceÄŸini ve bu projede neden doÄŸrudan bir Ã¶zellik olarak kullanÄ±lmadÄ±ÄŸÄ±nÄ± (Ã¶rneÄŸin, Word2Vec'in anlamsal temsildeki gÃ¼cÃ¼ nedeniyle) veya nasÄ±l entegre edilebileceÄŸini aÃ§Ä±klayÄ±n. Benzer ÅŸekilde, Edit Distance'Ä±n yazÄ±m dÃ¼zeltmedeki rolÃ¼nÃ¼ ve bu projede neden doÄŸrudan bir adÄ±m olarak eklenmediÄŸini (belki lemmatization'Ä±n kÄ±smi faydasÄ± veya projenin mevcut kapsamÄ± nedeniyle) belirtin.

3.  **Kod Kalitesi:**
    *   Jupyter Notebook ve Streamlit uygulamasÄ±ndaki kodlarÄ±n okunabilir ve anlaÅŸÄ±lÄ±r olduÄŸundan emin olun.

## SonuÃ§

Bu rehberdeki adÄ±mlarÄ± izleyerek projenizi baÅŸarÄ±lÄ± bir ÅŸekilde kurmuÅŸ, Ã§alÄ±ÅŸtÄ±rmÄ±ÅŸ ve test etmiÅŸ olmalÄ±sÄ±nÄ±z. BaÅŸarÄ±lar! 